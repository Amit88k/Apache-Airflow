1. provide the jar //DONE
5. location of jar -> ~/airflow  //DONE
2. setting up spark_home
3. steps to run spark job using spark_submit
4. Explaination of dag in tutorial.py
5. jar name and functionality conflict also update in calling_spark_job_dag.py //DONE
6. In local executor mode, steps for triggering the dag 
7. best practices add global() scope point 
8. delete a dag
